# -*- coding: utf-8 -*-
"""IrisDatasetProject1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12G093f3WtKA-M8Fy9J5bSlUGyGV0Hlmu

# **Importing Libraries**
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns


import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

"""# **Reading File Iris.csv**"""

df=pd.read_csv('Iris.csv')

"""# **Exploring DataSet**"""

df.head()

df.tail()

df.columns

df.shape

df.describe()

df.info()

"""# **Checking for Inconsistent Data**

*   Duplication
*   Null/Missing Values
*   Wrong DataTypes
*   Unnecessary Columns

# Duplication
"""

df.duplicated().sum()

"""# Null/Missing Values"""

df.isnull().sum()

"""# DataTypes

  





"""

df.dtypes

"""# Unnecessary Columns



*Dropping the column Id as it doesn't contain any useful information for analysis*
"""

df=df.drop(columns='Id')

"""# **Exploratory Data Analysis(EDA)**

*   Handling Outliers(if any)
*   Visualizing Data
*   Exploring Catagorical Data

# HandlingOutliers
"""

for col in df.columns:
  if col!='Species':

    sns.boxplot(x='Species' , y=col , data=df)
    plt.xlabel('Species')
    plt.ylabel(col)
    plt.title('Species vs %s' %col)
    plt.show()

"""*As we can observe that there are no outliers in the dataset *

# **Visualizing Data**


*   Countplot for all columns
*   Distribution of Sepal Length
*   Distribution of Sepal Width
*   Distribution of Petal Length
*   Distribution of Petal Width

# Countplot for all Columns
"""

#counting each instance of each column
plt.figure(figsize = (10,5))
sns.countplot(x='PetalLengthCm', data=df)
plt.xlabel('PetalLength')
plt.xticks(rotation=90)
plt.ylabel('count')
plt.title("countplot for PetalLength")
plt.show()

#counting each instance of each column
plt.figure(figsize = (10,5))
sns.countplot(x='PetalWidthCm', data=df)
plt.xlabel('PetalWidth')
plt.xticks(rotation=90)
plt.ylabel('count')
plt.title("countplot for PetalWidth")
plt.show()

#counting each instance of each column
plt.figure(figsize = (10,5))
sns.countplot(x='SepalLengthCm', data=df)
plt.xlabel('SepalWidth')
plt.xticks(rotation=90)
plt.ylabel('count')
plt.title("countplot for SepalLengthCm")
plt.show()

#counting each instance of each column
plt.figure(figsize = (10,5))
sns.countplot(x='SepalWidthCm', data=df)
plt.xlabel('SepalWidthCm')
plt.xticks(rotation=90)
plt.ylabel('count')
plt.title("countplot for SepalWidthCm")
plt.show()

"""# Distribution of Sepal Length"""

sns.histplot(x='SepalLengthCm',  data=df, kde=True)
plt.xlabel('Values')
plt.ylabel('Density')
plt.title('Distribution of SepalLength with KDE Plot')
plt.show()

"""***Normal Distribution***

# Distribution of Sepal Width
"""

# Visualizing Distribution Of SepalWidth
sns.histplot(x='SepalWidthCm',  data=df, kde=True)
plt.xlabel('Values')
plt.ylabel('Density')
plt.title('Distribution of SepalWidth with KDE Plot')
plt.show()

"""***Normal Distribution***

# Distribution of Petal Length
"""

sns.histplot(x='PetalLengthCm',  data=df, kde=True)
plt.xlabel('Values')
plt.ylabel('Density')
plt.title('Distribution of PetalLength with KDE Plot')
plt.show()

"""***Both Positive and Normal distribution can be seen***

# Distribution of Petal Width
"""

sns.histplot(x='PetalWidthCm',  data=df, kde=True)
plt.xlabel('Values')
plt.ylabel('Density')
plt.title('Distribution of PetalWidth with KDE Plot')
plt.show()

"""***Both Positive and Normal distribution can be seen***

# Exploring Catagorical Data(Target variable)


*   Countplot
*   Pairplot
*   Correlation Matrix
*   Heatmap
"""

#target variable is catagorical means that it contains types of data which is repeated

df.Species.value_counts()

#Countplot

sns.countplot(data=df, x='Species')
plt.show()

# Pairplot

sns.pairplot(df , hue='Species')
plt.title('pair plot')
plt.show()

"""***Through this pair plot we observe that iris setosa specie is always linearly sperable***"""

#correlation matrix

df.corr()

#correlation heatmap

corr_matrix=df.corr()
sns.heatmap(corr_matrix, annot=True)
plt.title('correlation heatmap')
plt.show()

"""# **Label Encoding**"""

df['Species']

"""***As we know that our target variable Species is catagorical and of object datatype so we need to perform label encoding***"""

#using label encoding for converting categories(character dtype) to numerical representation for making models models work on numerics only
#encoding categorical data
labelEncode=LabelEncoder()
df['Species']=labelEncode.fit_transform(df['Species'])

df['Species']

"""# **Splitting into Testing and Training Data**"""

X=df.drop(columns=['Species'])
Y=df['Species']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20)

X_test

Y_test

"""# **MACHINE LEARNING**



*   Logistic Regression
*   K-Nearest Neighbor
*   Decision Tree Classifier

# Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
model=LogisticRegression(verbose=40)

model.fit(X_train, Y_train)

print("Accuracy: ",model.score(X_test,Y_test)*100)

# Get predictions for all test instances
y_pred = model.predict(X_test)

from sklearn import metrics

print(metrics.classification_report(Y_test, y_pred))

#PRINTING THE CONFUSION MATRIX

print("Confusion Matrix\n\n")

print(metrics.confusion_matrix(Y_test, y_pred))

"""# K-Nearest Neighbor"""

from sklearn.neighbors import KNeighborsClassifier
model2= KNeighborsClassifier()

model2.fit(X_train, Y_train)

print("Accuracy: ",model2.score(X_test,Y_test)*100)

# Get predictions for all test instances
y_pred1 = model2.predict(X_test)

from sklearn import metrics

print(metrics.classification_report(Y_test, y_pred1))

#PRINTING THE CONFUSION MATRIX

print("Confusion Matrix\n\n")

print(metrics.confusion_matrix(Y_test, y_pred1))

"""# Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()

clf.fit(X_train, Y_train)

print("Accuracy: ",clf.score(X_test, Y_test)*100)

# Get predictions for all test instances
y_pred3 = clf.predict(X_test)

print(metrics.classification_report(Y_test, y_pred3))

#PRINTING THE CONFUSION MATRIX

print("Confusion Matrix\n\n")
print(metrics.confusion_matrix(Y_test, y_pred3))